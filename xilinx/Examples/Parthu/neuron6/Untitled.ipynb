{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a5b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfebaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a6029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ac15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb3007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4baf1d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x1656a\n",
      "result : 0b10110010101101010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "module neuron #(\n",
    "    parameter N = 2,       // Number of inputs -> \n",
    "    parameter WIDTH = 16,    // Bit width of inputs/weights/bias\n",
    "    parameter biasFile=\"\",\n",
    "    parameter weightFile=\"\"\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input   [N*WIDTH-1:0]  x_flat,       // Flattened inputs\n",
    "    output reg  [(2*WIDTH)-1:0]    y             // Output\n",
    "    );\n",
    "    // Internal register to hold the sum\n",
    "    reg signed [(2*WIDTH)-1:0] sum;\n",
    "    reg signed [WIDTH-1:0] bb [0:0];\n",
    "    reg signed [WIDTH-1:0] weight_mem [0:N-1];\n",
    "    reg signed [WIDTH-1:0] x [0:N-1];\n",
    "    \n",
    "    genvar i;\n",
    "    reg [255:0] filename;\n",
    "    initial begin\n",
    "            $readmemh(biasFile, bb, 0, 0);\n",
    "            $readmemh(weightFile, weight_mem);\n",
    "    end\n",
    "    \n",
    "    generate\n",
    "        for (i = 0; i < N; i = i + 1) begin : unpack_x_w\n",
    "            always @(*) begin\n",
    "                x[i] = x_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack x[i]\n",
    "            end\n",
    "        end\n",
    "    endgenerate\n",
    "    integer j;\n",
    "    always @(*) begin\n",
    "            sum = bb[0];\n",
    "            // Compute weighted sum\n",
    "            for (j = 0; j < N; j = j + 1) begin\n",
    "                sum = sum + (x[j] * weight_mem[j]);  // Multiply x[i] with w[i] and accumulate\n",
    "            end\n",
    "            // ReLU activation\n",
    "            if (sum < 0)\n",
    "                y <= 0;\n",
    "            else\n",
    "                y <= sum; // Truncate to WIDTH bits\n",
    "    end\n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`timescale 1ns / 1ps\n",
    "module layer2 #(\n",
    "    parameter N = 2,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 4,       // Number of neurons in this layer\n",
    "    parameter layer_num = 2          // layer number\n",
    ")\n",
    "( \n",
    "    input clk,\n",
    "    input reset,\n",
    "    output [(NUM_NEURONS*2*WIDTH)-1:0] y_flat            // Outputs from all neurons\n",
    "    );\n",
    "    reg [N*WIDTH-1:0] x; \n",
    "\n",
    "    initial begin\n",
    "        x = 32'h00490020;   // x1 = 0020, x2 = 0049\n",
    "    end    \n",
    "    // Instantiate neurons\n",
    "    genvar n;\n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neuron #(\n",
    "                .N(N),\n",
    "                .WIDTH(WIDTH),\n",
    "                .biasFile({\"b_\", layer_num[N:0] + \"0\" ,\"_\", n[N:0] + \"0\", \".mif\"}),\n",
    "                .weightFile({\"w_2_\",n[N:0] + \"0\", \".mif\"})\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron\n",
    "                .y(y_flat[(n*2*WIDTH) +: 2*WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate    \n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`timescale 1ns / 1ps\n",
    "\n",
    "module layer3 #(\n",
    "    parameter N = 4,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 2,       // Number of neurons in this layer\n",
    "    parameter layer_num = 3\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input  [2*N*WIDTH-1:0]    x,\n",
    "    output [4*NUM_NEURONS*WIDTH-1:0] y_flat\n",
    "    );\n",
    "    genvar n;\n",
    "    integer i;\n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neuron #(\n",
    "                .N(N),\n",
    "                .WIDTH(2*WIDTH),\n",
    "                .biasFile({\"b_3_\", n[N:0] + \"0\", \".mif\"}),\n",
    "                .weightFile({\"w_3_\",n[N:0] + \"0\", \".mif\"})\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron),\n",
    "                .y(y_flat[(4*n*WIDTH) +: 4*WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate\n",
    "endmodule\n",
    "\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "overlay = Overlay('two.bit')\n",
    "gpio_0 = MMIO(0x41200000,0x10000)\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4b9a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x37e0656a\n",
      "result : 0b110111111000000110010101101010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "`timescale 1ns / 1ps\n",
    "\n",
    "module neuron #(\n",
    "    parameter N = 2,       // Number of inputs -> \n",
    "    parameter WIDTH = 16,    // Bit width of inputs/weights/bias\n",
    "    parameter biasFile=\"\",\n",
    "    parameter weightFile=\"\"\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input   [N*WIDTH-1:0]  x_flat,       // Flattened inputs\n",
    "    output reg  [(2*WIDTH)-1:0]    y             // Output\n",
    "    );\n",
    "    // Internal register to hold the sum\n",
    "    reg signed [(2*WIDTH)-1:0] sum;\n",
    "    reg signed [WIDTH-1:0] bb [0:0];\n",
    "    reg signed [WIDTH-1:0] weight_mem [0:N-1];\n",
    "    reg signed [WIDTH-1:0] x [0:N-1];\n",
    "    \n",
    "    genvar i;\n",
    "    reg [255:0] filename;\n",
    "    initial begin\n",
    "            $readmemh(biasFile, bb, 0, 0);\n",
    "            $readmemh(weightFile, weight_mem);\n",
    "    end\n",
    "    \n",
    "    generate\n",
    "        for (i = 0; i < N; i = i + 1) begin : unpack_x_w\n",
    "            always @(*) begin\n",
    "                x[i] = x_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack x[i]\n",
    "            end\n",
    "        end\n",
    "    endgenerate\n",
    "    integer j;\n",
    "    always @(*) begin\n",
    "            sum = bb[0];\n",
    "            // Compute weighted sum\n",
    "            for (j = 0; j < N; j = j + 1) begin\n",
    "                sum = sum + (x[j] * weight_mem[j]);  // Multiply x[i] with w[i] and accumulate\n",
    "            end\n",
    "            // ReLU activation\n",
    "            if (sum < 0)\n",
    "                y <= 0;\n",
    "            else\n",
    "                y <= sum; // Truncate to WIDTH bits\n",
    "    end\n",
    "endmodule\n",
    "\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "overlay = Overlay('one.bit')\n",
    "gpio_0 = MMIO(0x41200000,0x10000)\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecab8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "module neu #(\n",
    "    parameter N = 2,       // Number of inputs -> \n",
    "    parameter WIDTH = 16,   // Bit width of inputs/weights/bias\n",
    "    parameter biasFile=\"\",\n",
    "    parameter weightFile=\"\"\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input   [N*WIDTH-1:0]  x_flat,       // Flattened inputs\n",
    "    input   [N*WIDTH-1:0]  w_flat,       // Flattened weights\n",
    "    input   [WIDTH-1:0]    b,            // Bias\n",
    "    input [N:0] layer_num,\n",
    "    input [N:0] neuron_num,\n",
    "    output reg  [WIDTH-1:0]    y             // Output\n",
    "    );\n",
    "\n",
    "    // Internal register to hold the sum\n",
    "    reg signed [31:0] sum;\n",
    "    reg signed [WIDTH-1:0] bb [0:0];\n",
    "    \n",
    "    // Declare registers to store individual x and w values\n",
    "    reg signed [WIDTH-1:0] x [0:N-1];\n",
    "    reg signed [WIDTH-1:0] w [0:N-1];\n",
    "    reg signed [WIDTH-1:0] weight_mem [0:N-1];\n",
    "    \n",
    "    genvar i;\n",
    "    integer j;\n",
    "    reg [255:0] filename;\n",
    "    initial begin\n",
    "            $readmemh(biasFile, bb, 0, 0);\n",
    "            $readmemh(weightFile, weight_mem);\n",
    "    end\n",
    "    generate\n",
    "        for (i = 0; i < N; i = i + 1) begin : unpack_x_w\n",
    "            always @(*) begin\n",
    "                x[i] = x_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack x[i]\n",
    "                w[i] = w_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack w[i]\n",
    "            end\n",
    "        end\n",
    "    endgenerate\n",
    "\n",
    "    always @(*) begin\n",
    "            sum = bb[0];\n",
    "            for (j = 0; j < N; j = j + 1) begin\n",
    "                sum = sum + (x[j] * weight_mem[j]);  // Multiply x[i] with w[i] and accumulate\n",
    "            end\n",
    "//             ReLU activation\n",
    "            if (sum < 0)\n",
    "                y <= 0;\n",
    "            else\n",
    "                y <= sum[WIDTH-1:0]; // Truncate to WIDTH bits\n",
    "    end\n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "module two #(\n",
    "    parameter N = 2,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 4,       // Number of neurons in this layer\n",
    "    parameter layer_num = 2          // layer number\n",
    ")\n",
    "( \n",
    "    input clk,\n",
    "    input reset,\n",
    "    output [NUM_NEURONS*WIDTH-1:0] y_flat            // Outputs from all neurons\n",
    "    );\n",
    "//  Internal registers to store unpacked weights, biases, and outputs\n",
    "    reg signed [WIDTH-1:0] b [0:NUM_NEURONS-1];           // 1D array for biases\n",
    "    reg [WIDTH-1:0] y [0:NUM_NEURONS-1];                 // Wire array for neuron outputs\n",
    "    reg signed [NUM_NEURONS*N*WIDTH-1:0] w;\n",
    "    reg signed [WIDTH-1:0] weight_mem [0:N-1];  // temporary memory to hold weights from file\n",
    "    reg [N*WIDTH-1:0] x;\n",
    "    reg [15:0] mem [0:15]; // A memory array\n",
    "    \n",
    "    genvar n;\n",
    "    integer i;\n",
    "    integer j;\n",
    "    reg [255:0] filename;\n",
    "\n",
    "    // bias initialization\n",
    "    initial begin         \n",
    "        x = 32'h00490020;   // x1 = 0020, x2 = 0049\n",
    "        w = 128'h00190020002100220023002400250026;   // w1 = 0026,  w2 = 0025,  w3 = 0024, w4 == 0023, w5 = 0022, w6 = 0021 w7 = \n",
    "\n",
    "    end    \n",
    "\n",
    "//    // Instantiate neurons\n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neu #(\n",
    "                .N(N),\n",
    "                .WIDTH(WIDTH),\n",
    "                .biasFile({\"b_\", layer_num[N:0] + \"0\" ,\"_\", n[N:0] + \"0\", \".mif\"}),\n",
    "                .weightFile({\"w_2_\",n[N:0] + \"0\", \".mif\"})\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron\n",
    "                .w_flat(w[(n*N + 0) * WIDTH +: N*WIDTH]),    // Flattened weights remain the same\n",
    "                .b(b[n]),           // Pass the corresponding bias for this neuron\n",
    "                .layer_num(layer_num),\n",
    "                .neuron_num(n),\n",
    "                .y(y_flat[(n*WIDTH) +: WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate\n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "module three #(\n",
    "    parameter N = 4,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 2,       // Number of neurons in this layer\n",
    "    parameter layer_num = 3\n",
    ")\n",
    "\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input  [N*WIDTH-1:0]    x,\n",
    "    output [NUM_NEURONS*WIDTH-1:0] y_flat\n",
    "    );\n",
    "    \n",
    "    reg signed [WIDTH-1:0] b [0:NUM_NEURONS-1];           // 1D array for biases\n",
    "    reg [NUM_NEURONS*N*WIDTH-1:0] w;\n",
    "    genvar n;\n",
    "    integer i;\n",
    "    \n",
    "    initial begin\n",
    "        w = 128'h00120011001000090008000700060005;   // w1 = 0026,  w2 = 0025,  w3 = 0024, w4 == 0023, w5 = 0022, w6 = 0021\n",
    "    end    \n",
    "    \n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neu #(\n",
    "                .N(N),\n",
    "                .WIDTH(WIDTH),\n",
    "                .biasFile({\"b_3_\", n[N:0] + \"0\", \".mif\"}),\n",
    "                .weightFile({\"w_3_\",n[N:0] + \"0\", \".mif\"})\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron\n",
    "                .w_flat(w[(n*N + 0) * WIDTH +: N*WIDTH]),    // Flattened weights remain the same\n",
    "                .b(b[n]),           // Pass the corresponding bias for this neuron\n",
    "                .layer_num(layer_num),\n",
    "                .neuron_num(n),\n",
    "                .y(y_flat[(n*WIDTH) +: WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate\n",
    "    \n",
    "endmodule\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('two.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(0x41200000,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")\n",
    "\n",
    "# giving result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ddff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x3500647a\n",
      "result : 0b110101000000000110010001111010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "`timescale 1ns / 1ps\n",
    "module neu #(\n",
    "    parameter N = 2,       // Number of inputs -> \n",
    "    parameter WIDTH = 16    // Bit width of inputs/weights/bias\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input   [N*WIDTH-1:0]  x_flat,       // Flattened inputs\n",
    "    input   [N*WIDTH-1:0]  w_flat,       // Flattened weights\n",
    "    input   [WIDTH-1:0]    b,            // Bias\n",
    "    input [N:0] layer_num,\n",
    "    input [N:0] neuron_num,\n",
    "    output reg  [WIDTH-1:0]    y             // Output\n",
    "    );\n",
    "    reg signed [31:0] sum;\n",
    "    reg signed [WIDTH-1:0] bb [0:0];\n",
    "    reg signed [WIDTH-1:0] x [0:N-1];\n",
    "    reg signed [WIDTH-1:0] w [0:N-1];\n",
    "    \n",
    "    genvar i;\n",
    "    integer j;\n",
    "    reg [255:0] filename;\n",
    "    \n",
    "    initial begin\n",
    "        filename = {\"b_\", layer_num[N:0] + \"0\" ,\"_\", neuron_num[N:0] + \"0\", \".mif\"};\n",
    "        $readmemh(\"b_2_0.mif\", bb, 0, 0);\n",
    "    end\n",
    "    \n",
    "    generate\n",
    "        for (i = 0; i < N; i = i + 1) begin : unpack_x_w\n",
    "            always @(*) begin\n",
    "                x[i] = x_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack x[i]\n",
    "                w[i] = w_flat[(i+1)*WIDTH-1 : i*WIDTH];  // Unpack w[i]\n",
    "            end\n",
    "        end\n",
    "    endgenerate\n",
    "\n",
    "    always @(*) begin\n",
    "            sum = bb[0];\n",
    "            for (j = 0; j < N; j = j + 1) begin\n",
    "                sum = sum + (x[j] * w[j]);  // Multiply x[i] with w[i] and accumulate\n",
    "            end\n",
    "            if (sum < 0)\n",
    "                y <= 0;\n",
    "            else\n",
    "                y <= sum[WIDTH-1:0]; // Truncate to WIDTH bits\n",
    "    end\n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "`timescale 1ns / 1ps\n",
    "module two #(\n",
    "    parameter N = 2,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 4,       // Number of neurons in this layer\n",
    "    parameter layer_num = 2          // layer number\n",
    ")\n",
    "( \n",
    "    input clk,\n",
    "    input reset,\n",
    "    output [NUM_NEURONS*WIDTH-1:0] y_flat            // Outputs from all neurons\n",
    "    );\n",
    "    reg signed [WIDTH-1:0] b [0:NUM_NEURONS-1];           // 1D array for biases\n",
    "    reg [WIDTH-1:0] y [0:NUM_NEURONS-1];                 // Wire array for neuron outputs\n",
    "    reg signed [NUM_NEURONS*N*WIDTH-1:0] w;\n",
    "    reg signed [WIDTH-1:0] weight_mem [0:N-1];  // temporary memory to hold weights from file\n",
    "    reg [N*WIDTH-1:0] x;\n",
    "    reg [15:0] mem [0:15]; // A memory array\n",
    "    \n",
    "    genvar n;\n",
    "    integer i;\n",
    "    integer j;\n",
    "    reg [255:0] filename;\n",
    "    initial begin         \n",
    "        x = 32'h00490020;   // x1 = 0020, x2 = 0049\n",
    "        w = 128'h00190020002100220023002400250026;   // w1 = 0026,  w2 = 0025,  w3 = 0024, w4 == 0023, w5 = 0022, w6 = 0021 w7 = \n",
    "    end    \n",
    "\n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neu #(\n",
    "                .N(N),\n",
    "                .WIDTH(WIDTH)\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron\n",
    "                .w_flat(w[(n*N + 0) * WIDTH +: N*WIDTH]),    // Flattened weights remain the same\n",
    "                .b(b[n]),           // Pass the corresponding bias for this neuron\n",
    "                .layer_num(layer_num),\n",
    "                .neuron_num(n),\n",
    "                .y(y_flat[(n*WIDTH) +: WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate\n",
    "endmodule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`timescale 1ns / 1ps\n",
    "module three #(\n",
    "    parameter N = 4,               // Number of inputs per neuron   ->  no of input\n",
    "    parameter WIDTH = 16,           // Bit width of inputs/weights/bias\n",
    "    parameter NUM_NEURONS = 2,       // Number of neurons in this layer\n",
    "    parameter layer_num = 3\n",
    ")\n",
    "(\n",
    "    input clk,\n",
    "    input reset,\n",
    "    input  [N*WIDTH-1:0]    x,\n",
    "    output [NUM_NEURONS*WIDTH-1:0] y_flat\n",
    "    );\n",
    "    \n",
    "    reg signed [WIDTH-1:0] b [0:NUM_NEURONS-1];           // 1D array for biases\n",
    "    reg [NUM_NEURONS*N*WIDTH-1:0] w;\n",
    "    genvar n;\n",
    "    integer i;\n",
    "    \n",
    "    initial begin\n",
    "        w = 128'h00120011001000090008000700060005;   // w1 = 0026,  w2 = 0025,  w3 = 0024, w4 == 0023, w5 = 0022, w6 = 0021\n",
    "    end    \n",
    "    \n",
    "    generate\n",
    "        for (n = 0; n < NUM_NEURONS; n = n + 1) begin : neuron_inst\n",
    "            neu #(\n",
    "                .N(N),\n",
    "                .WIDTH(WIDTH)\n",
    "            ) u_neuron (\n",
    "                .clk(clk),\n",
    "                .reset(reset),\n",
    "                .x_flat(x),    // Flattened input remains the same for each neuron\n",
    "                .w_flat(w[(n*N + 0) * WIDTH +: N*WIDTH]),    // Flattened weights remain the same\n",
    "                .b(b[n]),           // Pass the corresponding bias for this neuron\n",
    "                .layer_num(layer_num),\n",
    "                .neuron_num(n),\n",
    "                .y(y_flat[(n*WIDTH) +: WIDTH])            // Output of this neuron\n",
    "            );\n",
    "        end\n",
    "    endgenerate\n",
    "    \n",
    "endmodule\n",
    "\"\"\"\n",
    "\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('three.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daec1ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x15f00960\n",
      "result : 0b10101111100000000100101100000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "           $readmemh(\"data.mif\", mem);\n",
    "           for(j=0; j < NUM_NEURONS*N; j= j+1) begin\n",
    "                w[j*WIDTH +: WIDTH] = mem[(NUM_NEURONS * N -1) - j];\n",
    "           end\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('twentyfive.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0284ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x15f00960\n",
      "result : 0b10101111100000000100101100000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        $readmemh(\"w_2_0.mif\", weight_mem);\n",
    "        w[31:0] = {weight_mem[1], weight_mem[0]};\n",
    "        \n",
    "        $readmemh(\"w_2_1.mif\", weight_mem);\n",
    "        w[63:32] = {weight_mem[1], weight_mem[0]};\n",
    "        \n",
    "        $readmemh(\"w_2_2.mif\", weight_mem);\n",
    "        w[95:64] = {weight_mem[1], weight_mem[0]};\n",
    "        \n",
    "        $readmemh(\"w_2_3.mif\", weight_mem);\n",
    "        w[127:96] = {weight_mem[1], weight_mem[0]};\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('twentyfour.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd10467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x37e0656a\n",
      "result : 0b110111111000000110010101101010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "            w[31:0] = {16'h0025, 16'h0026};\n",
    "            w[63:32] = {16'h0023, 16'h0024};\n",
    "            w[95:64] = {16'h0021, 16'h0022};\n",
    "            w[127:96] = {16'h0019, 16'h0020};\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('twentythree.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c66181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x15f00960\n",
      "result : 0b10101111100000000100101100000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "            $readmemh(\"data.mif\", mem);\n",
    "           for(j=0; j < NUM_NEURONS*N; j= j+1) begin\n",
    "                w[j*WIDTH +: WIDTH] = mem[j];\n",
    "           end\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('twentytwo.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d0c0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : 0x52c87144\n",
      "result : 0b1010010110010000111000101000100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "        w[31:0] = {16'h0026, 16'h0025};\n",
    "        w[63:32] = {16'h0024, 16'h0023};\n",
    "        w[95:64] = {16'h0022, 16'h0021};\n",
    "        w[127:96] = {16'h0020, 16'h0019};\n",
    "\"\"\"\n",
    "from pynq import Overlay , MMIO\n",
    "\n",
    "overlay = Overlay('twentyone.bit')\n",
    "\n",
    "gpio_0_baseaddr = 0x41200000\n",
    "\n",
    "gpio_0 = MMIO(gpio_0_baseaddr,0x10000)\n",
    "\n",
    "result  = gpio_0.read(0x00)\n",
    "print(f\"result : {hex(result)}\")\n",
    "print(f\"result : {bin(result)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
